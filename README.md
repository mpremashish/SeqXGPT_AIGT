# SeqxGPT_AIGT_Project

AI text detection project, which helps detect if a corresponding sentence is being generated by an AI model or not and or also tell which model the text was generated from. We have provided a trained model here https://github.com/mpremashish/SeqXGPT_AIGT/blob/main/SeqXGPT_AIGT/linear_en.pt, you can use this , directly just generate the train and test data and run the  command in the test phase.

Also if you want use already generated data and features, you can find them in drive: https://drive.google.com/drive/folders/1oMzO2yEgfwaV1A21Kz0ekxas_TP4aTSR?usp=drive_link, https://drive.google.com/file/d/11iohNH10KodPw0g22esQvWcG8jTUDLjq/view?usp=drive_link.

# Data Generation

All the data files for corresponding models can found inside : https://github.com/mpremashish/SeqXGPT_AIGT/tree/main/SeqXGPT_AIGT/dataset/SeqXGPT-Bench. We have to merge all these sentences to have entire data for our model to train. Merging can automatically done using the notebook mentioned below.

# Feature Generation

Need to deploy api's corresponding to various models for inference of perplexities present in https://github.com/mpremashish/SeqXGPT_AIGT/blob/main/SeqXGPT_AIGT/backend_model.py, commands for the api deployment:

```
python backend_api.py --port 6006 --timeout 30000 --debug --model=gpt2 --gpu=0
python backend_api.py --port 6007 --timeout 30000 --debug --model=gptneo --gpu=0
python backend_api.py --port 6008 --timeout 30000 --debug --model=gptj --gpu=0
python backend_api.py --port 6009 --timeout 30000 --debug --model=llama --gpu=0
```

Once we have deployed our model and all the models are exposed as an api, we can get the features and form new files by running the note book : https://github.com/mpremashish/SeqXGPT_AIGT/blob/main/SeqXGPT_AIGT/dataset/gen_feature.ipynb

We will get the following files as output:

```
1) input.jsonl
2) output_all.jsonl
3) output_ prompt_merged.jsonl
4) output_binary_merged.jsonl
```

Significant files for training are output_ prompt_merged.jsonl and output_binary_merged.jsonl. 

```
1) output_ prompt_merged.jsonl for Mixed-Model Multiclass
2) output_binary_merged.jsonl for Mixed-Model Binary
```

Move them accordingly for training to https://github.com/mpremashish/SeqXGPT_AIGT/tree/main/SeqXGPT_AIGT/SeqXGPT (Warning: dont move both of them together, first one when training for multiclass and 2 one for binary classificaiton)


# Training Generation

For training for multiclass, run  (run in the model in following https://github.com/mpremashish/SeqXGPT_AIGT/tree/main/SeqXGPT_AIGT):

```
python ./SeqXGPT/train.py --gpu=0 --split_dataset --data_path=./SeqXGPT --train_path=./SeqXGPT/train.jsonl --test_path=./SeqXGPT/test.jsonl
```

For training for binary, run  (run in the model in following https://github.com/mpremashish/SeqXGPT_AIGT/tree/main/SeqXGPT_AIGT):

```
python ./SeqXGPT/train.py --gpu=0 --split_dataset --data_path=./SeqXGPT --train_path=./SeqXGPT/train.jsonl --test_path=./SeqXGPT/test.jsonl --mixed_model_binary
```

# Testing

For running on test mode with saved model: 

```
python ./SeqXGPT/train.py --gpu=0 --do_test --test_path=./SeqXGPT/test.jsonl --train_path=./SeqXGPT/train.jsonl
```

# Error Analysis

After Test you will find a error analysis file named errors_analysis for 5 text that were not properly classified.

# Multilingual

We made the model lingual by making tokenization changes and using different perplexity generation models. We made model multilingual especially to understand french and chinese. We need to train on the top of already trained model, following command we help up us achieve that. All the multilingual dataset can be found in drive provided above

```
python ./SeqXGPT/train.py --gpu=0 --split_dataset --data_path=./SeqXGPT --train_path=./SeqXGPT/train.jsonl --test_path=./SeqXGPT/test.jsonl --used_saved_model
```
